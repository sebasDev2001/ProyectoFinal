{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch and tf/keras learning",
      "provenance": [],
      "authorship_tag": "ABX9TyNMZNxzVUYwa7Y6x+0xFu7S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebasDev2001/ProyectoFinal/blob/main/Pytorch_and_tf_keras_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning Pythorch and more tk/keras ml**\n",
        "\n"
      ],
      "metadata": {
        "id": "fLq3BM3wz5WD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Rx40Jiub5QH"
      },
      "source": [
        "# Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8P9zFq5byOa"
      },
      "source": [
        "from sklearn.datasets import load_files       \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dropout, Flatten, Conv2D,MaxPooling2D, Dense, Activation, SeparableConv2D, AveragePooling2D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "import os\n",
        "from glob import glob # para recojer los datos mas facil\n",
        "from tqdm import trange\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from os import makedirs\n",
        "from os import listdir\n",
        "from shutil import copyfile\n",
        "from random import seed\n",
        "from random import random\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "def read_image(file_path, ROWS = 64,COLS = 64):\n",
        "  img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
        "  return cv2.resize(img, (ROWS, COLS))\n",
        "\n",
        "def prep_data(images, ROWS = 64,COLS = 64,CHANNELS=3):\n",
        "  count = len(images)\n",
        "  data = np.ndarray((count, ROWS, COLS, CHANNELS))\n",
        "  for i, image_file in enumerate(images):\n",
        "    image = read_image(image_file,ROWS,COLS)\n",
        "    data[i] = image   \n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0ooLf8rb_AI",
        "outputId": "f2264741-6d18-4d45-a587-797b109b8bf4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl3rDAdHcAU6"
      },
      "source": [
        "!ls \"/content/drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fME-WYmccGwL"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/archive.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp3sHHkucUaT"
      },
      "source": [
        "#getting images\n",
        "classes = ['cane', 'cavallo', 'elefante', 'farfalla', 'gallina', 'gatto', 'mucca', 'pecora', 'ragno', 'scoiattolo']\n",
        "\n",
        "dir = '/content/raw-img'\n",
        "imagesPre = []\n",
        "for tipo in classes:\n",
        "  aux = classes.index(tipo)\n",
        "  path = os.path.join(dir, tipo)\n",
        "  for img in os.listdir(path):\n",
        "    try:\n",
        "      dir2 = os.path.join(path, img)\n",
        "      #img = cv2.imread(dir)\n",
        "      imagesPre.append([dir2, aux])\n",
        "      #imagesLabels.append(aux)\n",
        "    except Exception as e:\n",
        "      pass\n",
        "\n",
        "random.shuffle(imagesPre)\n",
        "'''for i in images[:10]:\n",
        "    print(classes[i[1]])'''\n",
        "images = []\n",
        "imagesLabels = []\n",
        "\n",
        "for i in imagesPre:\n",
        "  images.append(i[0])\n",
        "  imagesLabels.append(i[1])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szmq6RI4kIHN"
      },
      "source": [
        "imagesLabels = np.array(imagesLabels)\n",
        "images = np.array(images)\n",
        "imagesLabels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW-FpuAPSIlJ"
      },
      "source": [
        "np.unique(imagesLabels,return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images"
      ],
      "metadata": {
        "id": "VNJTayHnUDsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67JHMPldeD4q"
      },
      "source": [
        "#image to data\n",
        "ROWS = 64\n",
        "COLS = 64\n",
        "CHANNELS = 3\n",
        "images = prep_data(images,ROWS=ROWS,COLS=COLS)\n",
        "images = images/255.0\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtkRUe4AuNSn"
      },
      "source": [
        "data = images.astype(np.float64)\n",
        "data = 255 * data\n",
        "images = data.astype(np.uint8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vuh_ly2wWQs",
        "outputId": "29a7c875-187a-47e0-ba99-b497e1c3c742"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26179, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1N9KSqpetzu"
      },
      "source": [
        "plt.figure(figsize=(15,20))\n",
        "for i in range(100):\n",
        "    plt.subplot(10,10,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(images[i])\n",
        "    plt.xlabel(classes[imagesLabels[i]])\n",
        "    #plt.xlabel(classes[imagesLabels[i]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLzjGNgeylHq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(images,imagesLabels, test_size=0.2, random_state=7, stratify=imagesLabels) #stratify es equitativo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIvRnPNecZbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7335c2c5-46ef-400c-9cb3-0773bb46a1bc"
      },
      "source": [
        "test = X_train.copy()\n",
        "type(test[0][0][0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.uint8"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhJRt7KzzI6u"
      },
      "source": [
        "test = (test/255).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiBRlKXszMXp"
      },
      "source": [
        "test[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-996JnsZ2cu"
      },
      "source": [
        "#Torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MtApUfcgI90"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class learnNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(learnNet,self).__init__()\n",
        "    '''self.conv1 = nn.Conv2D(3, 6, 4)\n",
        "    self.act1 = nn.ReLu()\n",
        "    self.conv2 = nn.Conv2D(6, 10, 4)\n",
        "    self.conv3 = nn.Conv2D(10, 16, 4) #58\n",
        "    self.pool = nn.MaxPooling2D(2,2) #29'''\n",
        "    self.l1 = nn.Linear(64*64,2048)\n",
        "    self.l2 = nn.Linear(2048,512)\n",
        "    self.l3 = nn.Linear(512, 100)\n",
        "    self.l4 = nn.Linear(100, 10)\n",
        "    self.act = nn.ReLU()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print(x.shape)\n",
        "    x = self.l1(x)\n",
        "    #print(x.shape)\n",
        "    x = self.act(x)\n",
        "    x = self.l2(x)\n",
        "    #print(x.shape)\n",
        "    x = self.act(x)\n",
        "    x = self.l3(x)\n",
        "    #print(x.shape)\n",
        "    x = self.act(x)\n",
        "    x = self.l4(x)\n",
        "    #print(x.shape)\n",
        "    return x \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGRI5J0AbgBa",
        "outputId": "b59be4d5-e1d0-4035-d1fb-10b2798e0fa3"
      },
      "source": [
        "X_train.reshape((-1,64,64))\n",
        "\n",
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.87058824, 0.81176471, 0.7372549 ],\n",
              "        [0.85882353, 0.80392157, 0.7254902 ],\n",
              "        [0.86666667, 0.80784314, 0.72941176],\n",
              "        ...,\n",
              "        [0.8627451 , 0.78431373, 0.71372549],\n",
              "        [0.85882353, 0.78039216, 0.71372549],\n",
              "        [0.8627451 , 0.78431373, 0.71764706]],\n",
              "\n",
              "       [[0.87843137, 0.81568627, 0.74901961],\n",
              "        [0.86666667, 0.80392157, 0.7372549 ],\n",
              "        [0.87843137, 0.81568627, 0.74901961],\n",
              "        ...,\n",
              "        [0.85098039, 0.78039216, 0.73333333],\n",
              "        [0.85098039, 0.78039216, 0.73333333],\n",
              "        [0.84313725, 0.77647059, 0.7254902 ]],\n",
              "\n",
              "       [[0.88235294, 0.81568627, 0.75686275],\n",
              "        [0.87058824, 0.80784314, 0.74509804],\n",
              "        [0.90196078, 0.83921569, 0.77647059],\n",
              "        ...,\n",
              "        [0.83137255, 0.76470588, 0.7372549 ],\n",
              "        [0.84705882, 0.77647059, 0.74901961],\n",
              "        [0.84705882, 0.78039216, 0.75294118]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.38039216, 0.69411765, 0.82352941],\n",
              "        [0.49411765, 0.78823529, 0.92156863],\n",
              "        [0.48627451, 0.76862745, 0.90588235],\n",
              "        ...,\n",
              "        [0.32941176, 0.6745098 , 0.76470588],\n",
              "        [0.34901961, 0.68235294, 0.78039216],\n",
              "        [0.38431373, 0.68627451, 0.78823529]],\n",
              "\n",
              "       [[0.49803922, 0.79215686, 0.91764706],\n",
              "        [0.51764706, 0.81176471, 0.9372549 ],\n",
              "        [0.48627451, 0.76470588, 0.89411765],\n",
              "        ...,\n",
              "        [0.3254902 , 0.68235294, 0.78431373],\n",
              "        [0.46666667, 0.81568627, 0.92156863],\n",
              "        [0.43529412, 0.76078431, 0.87058824]],\n",
              "\n",
              "       [[0.50980392, 0.8       , 0.9254902 ],\n",
              "        [0.45098039, 0.74509804, 0.87058824],\n",
              "        [0.45882353, 0.75294118, 0.87843137],\n",
              "        ...,\n",
              "        [0.4       , 0.75294118, 0.85882353],\n",
              "        [0.39607843, 0.74117647, 0.83921569],\n",
              "        [0.40784314, 0.73333333, 0.81960784]]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0uQRJXydVHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7e2211-50d9-4724-f3be-c8e1ef804650"
      },
      "source": [
        "model = learnNet()\n",
        "X = torch.tensor(X_train[2].reshape((-1,64*64))).float()\n",
        "Y = torch.tensor(Y_train[2]).long()\n",
        "out = model(X)\n",
        "cat = torch.argmax(out, dim=1)\n",
        "acc = (cat == Y ).float().mean()\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfQT0O5HxgBG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "3aa8ec1d-7da5-4515-cc95-22aad8ec028b"
      },
      "source": [
        "model = learnNet()\n",
        "BS = 30\n",
        "optim = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "losses , accuracies = [], []\n",
        "for i in range(100): #10 epocas\n",
        "  selection = np.random.randint(0,X_train.shape[0], size=(BS))\n",
        "  X = torch.tensor(X_train[selection].reshape((-1,64*64))).float()\n",
        "  Y = torch.tensor(Y_train[selection]).long()\n",
        "  print(Y,\"hi\")\n",
        "  optim.zero_grad()\n",
        "  out = model(X)\n",
        "  cat = torch.argmax(out, dim=1)\n",
        "  acc = (cat == Y ).float().mean()\n",
        "  loss = loss_func(out, Y)\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "  loss, accuracy = loss.item(), acc.item()\n",
        "  losses.append(loss)\n",
        "  accuracies.append(accuracy) \n",
        "  print('loss %.2f accuracy %.2f' % (loss, accuracy))\n",
        "\n",
        "plt.ylim(0,2)\n",
        "plt.plot(losses)\n",
        "plt.plot(accuracies)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 8, 5, 6, 2, 8, 5, 3, 0, 4, 3, 4, 7, 3, 7, 8, 4, 8, 5, 0, 4, 0, 3, 6,\n",
            "        8, 5, 0, 8, 0, 3]) hi\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8b2b2dd64ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (90) must match the size of tensor b (30) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0Ms7n70Zxla"
      },
      "source": [
        "#Tensorflow MNEST\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_asni521vDk"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver) #estrategia para distrbibuir en los tensor cores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 && Model 2"
      ],
      "metadata": {
        "id": "NKwhCkOdIBmB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTrb7Lsv7Z2G"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(SeparableConv2D(64, (3, 3), input_shape = (32, 32, 3), activation = 'relu', padding='same'))\n",
        "  \n",
        "  model.add(Conv2D(64, (3, 3), activation = 'relu',padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "  model.add(Conv2D(128, (3, 3), activation = 'relu',padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "  model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
        "  model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
        "  #model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units = 64, activation = 'relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(units = 10, activation = 'softmax'))\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy','mse'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzBZKZX_7-71"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHqu6pdAXIWg"
      },
      "source": [
        "with strategy.scope():\n",
        "  model=Sequential()\n",
        "  model.add(Conv2D(32,kernel_size=(3,3),input_shape=(64,64,3), padding='same'))\n",
        "  model.add(Conv2D(32,kernel_size=(3,3)))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Conv2D(32,kernel_size=(2,2)))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation=tf.nn.relu))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(10, activation=tf.nn.softmax))\n",
        "  model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy','mse'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkX20uspX55x"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using MobileNetV3 "
      ],
      "metadata": {
        "id": "pMOA_6bxH8kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im_size = (32,32,3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-rIodmRGpkg",
        "outputId": "303b3a42-025b-432c-ef66-877a1a50a9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  basenet = tf.keras.applications.MobileNetV2(input_shape=im_size,include_top=False, weights='imagenet')\n",
        "  basenet.trainable = False\n",
        "  NewModel = Sequential()\n",
        "  NewModel.add(basenet)\n",
        "  NewModel.add(Flatten())\n",
        "  NewModel.add(Dense(128, activation=tf.nn.relu))\n",
        "  #NewModel.add(Dropout(0.2))\n",
        "  NewModel.add(Dense(10, activation=tf.nn.softmax))\n",
        "  NewModel.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy', 'mse'])\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht3XjxmLIJTV",
        "outputId": "b893a71c-949f-44c6-f62b-ed290e8c1926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NewModel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X24xL8P5MTav",
        "outputId": "5decd9c0-da58-43f3-d337-5b59dfd2ea74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 1, 1, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               163968    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,423,242\n",
            "Trainable params: 165,258\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NewModel.evaluate(test_X,test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXM1aWUOJPV_",
        "outputId": "2e9c7941-533f-4dc8-e290-b7d70746ef0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 16s 26ms/step - loss: 2.2993 - accuracy: 0.1030 - mse: 27.6101\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.2993111610412598, 0.10300000011920929, 27.610126495361328]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdF__iyI8PRE"
      },
      "source": [
        "from keras.datasets import mnist, cifar10 \n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food101_imges, labels = image, label = tfds.as_numpy(tfds.load(\n",
        "    'food101',\n",
        "    split='test',\n",
        "    batch_size=-1,\n",
        "    as_supervised=True,\n",
        "))"
      ],
      "metadata": {
        "id": "3TOZN5WRuytb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5-Ojb0tYymX"
      },
      "source": [
        "(train_X, train_y), (test_X, test_y) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxeUTGP0MkUE",
        "outputId": "fe9ec96c-e5a9-43ad-b1e5-cb57206b8fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSPI4v3jY0Ek"
      },
      "source": [
        "train_X, test_X = train_X/255.0, test_X/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(train_X,train_y, test_size=0.2, random_state=7, stratify=train_y)"
      ],
      "metadata": {
        "id": "OmOpVmQdqUpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZcKCixxY6GM",
        "outputId": "bc0ef084-fece-4c74-ea79-835ba9f4c684"
      },
      "source": [
        "NewModel.fit(X_train,Y_train, epochs=10, validation_data=(X_val,Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 37s 24ms/step - loss: 1.9370 - accuracy: 0.3015 - mse: 27.6175 - val_loss: 1.8816 - val_accuracy: 0.3130 - val_mse: 27.6198\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.8303 - accuracy: 0.3344 - mse: 27.6207 - val_loss: 1.8480 - val_accuracy: 0.3273 - val_mse: 27.6213\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.7908 - accuracy: 0.3488 - mse: 27.6218 - val_loss: 1.8364 - val_accuracy: 0.3330 - val_mse: 27.6221\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.7628 - accuracy: 0.3588 - mse: 27.6226 - val_loss: 1.8239 - val_accuracy: 0.3381 - val_mse: 27.6233\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.7391 - accuracy: 0.3683 - mse: 27.6233 - val_loss: 1.8223 - val_accuracy: 0.3376 - val_mse: 27.6233\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.7202 - accuracy: 0.3732 - mse: 27.6238 - val_loss: 1.8203 - val_accuracy: 0.3421 - val_mse: 27.6246\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.7025 - accuracy: 0.3806 - mse: 27.6245 - val_loss: 1.8190 - val_accuracy: 0.3411 - val_mse: 27.6247\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.6874 - accuracy: 0.3847 - mse: 27.6249 - val_loss: 1.8201 - val_accuracy: 0.3437 - val_mse: 27.6252\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.6735 - accuracy: 0.3914 - mse: 27.6254 - val_loss: 1.8172 - val_accuracy: 0.3457 - val_mse: 27.6253\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.6602 - accuracy: 0.3967 - mse: 27.6258 - val_loss: 1.8216 - val_accuracy: 0.3439 - val_mse: 27.6261\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb30e80bb90>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_X,test_y, verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM0xFHoXt5SJ",
        "outputId": "c29a36c7-3452-4253-b1df-3942c514d21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 3s - loss: 0.8281 - accuracy: 0.7500 - mse: 27.6754 - 3s/epoch - 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8280676603317261, 0.75, 27.675443649291992]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getOneImage(dir, length, width):\n",
        "  from PIL import Image\n",
        "  from tensorflow.keras.preprocessing import image\n",
        "  img = image.load_img(dir, target_size=(length,width))\n",
        "  arrimg = image.img_to_array(img)\n",
        "  arrimg = np.array([arrimg])\n",
        "  return arrimg.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "O5JVIJ3eVwB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat = getOneImage('gato.jpg',64,64)"
      ],
      "metadata": {
        "id": "tdNYfXBFWeHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat[0]"
      ],
      "metadata": {
        "id": "fF-goKupcZQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(model.predict(cat), axis=-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG-SL0ijXRUg",
        "outputId": "cb61e9d7-5787-4d00-a1d6-667ec9cc6982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horse = getOneImage('caballo.jpg',64,64)"
      ],
      "metadata": {
        "id": "hqYQo8nPXYwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(model.predict(horse), axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRgoyfMSWyl0",
        "outputId": "0939043e-2eca-4725-824a-d2ab73405426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mar = getOneImage('mariposa.jpg',64,64)"
      ],
      "metadata": {
        "id": "nu_jL-CqWksd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH4bpSCdF5Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147ae1ef-1e67-4a54-d742-e238733d67a2"
      },
      "source": [
        "np.argmax(model.predict(mar), axis=-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "meDUYICTWp6a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}